{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f795fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from transformers import BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "667e1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf349bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'children'  # crime_book\n",
    "data_name = 'goodreads_reviews_children' # reviews_Electronics_5, \n",
    "output_dir='xxx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baddf92",
   "metadata": {},
   "source": [
    "# read review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba7e9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 734640/734640 [00:04<00:00, 161640.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# read raw data\n",
    "with open(f'{dataset}/{data_name}.json') as f:\n",
    "    data = []\n",
    "    readin = f.readlines()\n",
    "    for line in tqdm(readin):\n",
    "        data.append(json.loads(line))\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6ff75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "734640"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "931180b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': '160d1c77ab7241b4439826555c9ba7bd',\n",
       " 'book_id': '24396876',\n",
       " 'review_id': '3daf5e7c037a0235c676921f02c47021',\n",
       " 'rating': 5,\n",
       " 'review_text': 'Great story about surviving middle school and really finding yourself. With a wonderful dose of science neatly holding it all together. I read this in one sitting, I could not put it down.',\n",
       " 'date_added': 'Thu Oct 20 17:58:02 -0700 2016',\n",
       " 'date_updated': 'Thu Oct 20 20:52:56 -0700 2016',\n",
       " 'read_at': 'Thu Oct 20 00:00:00 -0700 2016',\n",
       " 'started_at': 'Thu Oct 20 00:00:00 -0700 2016',\n",
       " 'n_votes': 0,\n",
       " 'n_comments': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49f8fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text processing function\n",
    "def text_process(text):\n",
    "    p_text = ' '.join(text.split('\\r\\n'))\n",
    "    p_text = ' '.join(text.split('\\n\\r'))\n",
    "    p_text = ' '.join(text.split('\\n'))\n",
    "    p_text = ' '.join(p_text.split('\\t'))\n",
    "    p_text = ' '.join(p_text.split('\\rm'))\n",
    "    p_text = ' '.join(p_text.split('\\r'))\n",
    "    p_text = ''.join(p_text.split('$'))\n",
    "    p_text = ''.join(p_text.split('*'))\n",
    "\n",
    "    return p_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "139bfffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 734640/734640 [00:00<00:00, 1290694.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {4: 253185, 5: 251400, 0: 31113, 3: 148210, 1: 10726, 2: 40006})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## rate distribution\n",
    "\n",
    "rate_dict = defaultdict(int)\n",
    "\n",
    "for d in tqdm(data):\n",
    "    rate_dict[d['rating']] += 1\n",
    "    \n",
    "print(rate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c0eff9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 734640/734640 [00:07<00:00, 101765.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blank review:0\n",
      "Number of user:92667, Number of item:123946\n",
      "user_pos_reviews.len:81071,user_neg_reviews.len:38237\n",
      "item_pos_reviews.len:95458,item_neg_reviews.len:73154\n",
      "user.avg.pos_review:5.44514228366085,user.avg.neg_review:2.1468483926316813\n",
      "item.avg.pos_review:4.071006728736708,item.avg.neg_review:1.6050699498168557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## user/item statistics\n",
    "### we see 5 score as positive edge(review), 1-4 as negative ones.\n",
    "### user_pos_reviews/user_neg_reviews: key<-userID, value<-list(reviews)\n",
    "### item_pos_reviews/item_neg_reviews: key<-productID, value<-list(reviews)\n",
    "### user_reviews_dict/item_reviews_dict: key<-userID/productID, value<-list(tuple(reviews,p/n))\n",
    "\n",
    "user_pos_reviews = defaultdict(list)\n",
    "user_neg_reviews = defaultdict(list)\n",
    "item_pos_reviews = defaultdict(list)\n",
    "item_neg_reviews = defaultdict(list)\n",
    "user_set = set()\n",
    "item_set = set()\n",
    "\n",
    "user_reviews_dict = defaultdict(list)\n",
    "item_reviews_dict = defaultdict(list)\n",
    "\n",
    "blank_review_cnt = 0\n",
    "\n",
    "for d in tqdm(data):\n",
    "    if 'review_text' not in d:\n",
    "        blank_review_cnt += 1\n",
    "        continue\n",
    "    \n",
    "    text = text_process(d['review_text'])\n",
    "    user_set.add(d['user_id'])\n",
    "    item_set.add(d['book_id'])\n",
    "    if d['rating'] in [5.0, 4.0]:\n",
    "        user_pos_reviews[d['user_id']].append(text)\n",
    "        item_pos_reviews[d['book_id']].append(text)\n",
    "        \n",
    "        user_reviews_dict[d['user_id']].append((text,d['book_id'],1))\n",
    "        item_reviews_dict[d['book_id']].append((text,d['user_id'],1))\n",
    "    elif d['rating'] in [1,2,3,0]:\n",
    "        user_neg_reviews[d['user_id']].append(text)\n",
    "        item_neg_reviews[d['book_id']].append(text)\n",
    "        \n",
    "        user_reviews_dict[d['user_id']].append((text,d['book_id'],0))\n",
    "        item_reviews_dict[d['book_id']].append((text,d['user_id'],0))\n",
    "    else:\n",
    "        raise ValueError('Error!')\n",
    "        \n",
    "print(f'Number of blank review:{blank_review_cnt}')\n",
    "print(f'Number of user:{len(user_set)}, Number of item:{len(item_set)}')\n",
    "print(f'user_pos_reviews.len:{len(user_pos_reviews)},user_neg_reviews.len:{len(user_neg_reviews)}')\n",
    "print(f'item_pos_reviews.len:{len(item_pos_reviews)},item_neg_reviews.len:{len(item_neg_reviews)}')\n",
    "print(f'user.avg.pos_review:{(rate_dict[5]+rate_dict[4])/len(user_set)},user.avg.neg_review:{(rate_dict[1]+rate_dict[2]+rate_dict[3])/len(user_set)}')\n",
    "print(f'item.avg.pos_review:{(rate_dict[5]+rate_dict[4])/len(item_set)},item.avg.neg_review:{(rate_dict[1]+rate_dict[2]+rate_dict[3])/len(item_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "691d2a4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92667/92667 [00:02<00:00, 36986.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of item appearing in train_set:99369 or 99369\n",
      "Train/Val/Test size:463031,67801,203808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## split train/val/test as 7:1:2 or 8:1:1\n",
    "### user_pos_reviews/user_neg_reviews: key<-userID, value<-list(reviews)\n",
    "### item_pos_reviews/item_neg_reviews: key<-productID, value<-list(reviews)\n",
    "### train_user_neighbor: key<-userID, value<-list(tuple(reviews,p/n))\n",
    "### train_item_neighbor: key<-userID, value<-list(tuple(reviews,p/n))\n",
    "\n",
    "sample_num = len(data)\n",
    "random.seed(0)\n",
    "\n",
    "train_tuples = []\n",
    "val_tuples = []\n",
    "test_tuples = []\n",
    "train_item_set = set()\n",
    "user_id2idx = {}\n",
    "item_id2idx = {}\n",
    "train_user_pos_neighbor = defaultdict(list)\n",
    "train_user_neg_neighbor = defaultdict(list)\n",
    "train_item_pos_neighbor = defaultdict(list)\n",
    "train_item_neg_neighbor = defaultdict(list)\n",
    "\n",
    "c1 = 0\n",
    "c2 = 0\n",
    "c3 = 0\n",
    "\n",
    "for uid in tqdm(user_reviews_dict):\n",
    "    if uid not in user_id2idx:\n",
    "        user_id2idx[uid] = len(user_id2idx)\n",
    "    random.shuffle(user_reviews_dict[uid])\n",
    "    \n",
    "    for i in range(int(len(user_reviews_dict[uid])*0.7)):\n",
    "    #for i in range(int(len(user_reviews_dict[uid])*0.8)):\n",
    "        train_tuples.append((uid,user_reviews_dict[uid][i]))\n",
    "        train_item_set.add(user_reviews_dict[uid][i][1])\n",
    "        \n",
    "        # add to item_id2idx\n",
    "        if user_reviews_dict[uid][i][1] not in item_id2idx:\n",
    "            item_id2idx[user_reviews_dict[uid][i][1]] = len(item_id2idx)\n",
    "\n",
    "        # add to train_user_neighbor/train_item_neighbor\n",
    "        if user_reviews_dict[uid][i][2] == 1:\n",
    "            train_user_pos_neighbor[uid].append(user_reviews_dict[uid][i])\n",
    "            train_item_pos_neighbor[user_reviews_dict[uid][i][1]].append((user_reviews_dict[uid][i][0],uid,user_reviews_dict[uid][i][2]))\n",
    "        elif user_reviews_dict[uid][i][2] == 0:\n",
    "            train_user_neg_neighbor[uid].append(user_reviews_dict[uid][i])\n",
    "            train_item_neg_neighbor[user_reviews_dict[uid][i][1]].append((user_reviews_dict[uid][i][0],uid,user_reviews_dict[uid][i][2]))\n",
    "        else:\n",
    "            raise ValueError('Error!')\n",
    "            \n",
    "    for i in range(int(len(user_reviews_dict[uid])*0.7),int(len(user_reviews_dict[uid])*0.8)):\n",
    "    #for i in range(int(len(user_reviews_dict[uid])*0.8),int(len(user_reviews_dict[uid])*0.9)):\n",
    "        val_tuples.append((uid,user_reviews_dict[uid][i]))\n",
    "\n",
    "    for i in range(int(len(user_reviews_dict[uid])*0.8),len(user_reviews_dict[uid])):\n",
    "    #for i in range(int(len(user_reviews_dict[uid])*0.9),len(user_reviews_dict[uid])):\n",
    "        test_tuples.append((uid,user_reviews_dict[uid][i]))\n",
    "\n",
    "        \n",
    "    #c1 += int(len(user_reviews_dict[uid])*0.8)\n",
    "    #c2 += int(len(user_reviews_dict[uid])*0.9)-int(len(user_reviews_dict[uid])*0.8)\n",
    "    #c3 += len(user_reviews_dict[uid])-int(len(user_reviews_dict[uid])*0.9)\n",
    "    #print(c1,c2,c3)\n",
    "        \n",
    "print(f'Number of item appearing in train_set:{len(train_item_set)} or {len(item_id2idx)}')\n",
    "print(f'Train/Val/Test size:{len(train_tuples)},{len(val_tuples)},{len(test_tuples)}')\n",
    "#print(c1,c2,c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6e668bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 463031/463031 [11:23<00:00, 677.16it/s] \n"
     ]
    }
   ],
   "source": [
    "# generate and save train file\n",
    "## user pos neighbor: 8, user neg neighbor: 8\n",
    "## item pos neighbor: 10, item neg neighbor: 10\n",
    "\n",
    "upos = 6\n",
    "uneg = 3\n",
    "ipos = 4\n",
    "ineg = 2\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "with open(f'{output_dir}/{dataset}/train.tsv','w') as fout:\n",
    "    for d in tqdm(train_tuples):\n",
    "        \n",
    "        # prepare sample pool for user and item\n",
    "        user_pos_pool = set(deepcopy(train_user_pos_neighbor[d[0]]))\n",
    "        user_neg_pool = set(deepcopy(train_user_neg_neighbor[d[0]]))\n",
    "        item_pos_pool = set(deepcopy(train_item_pos_neighbor[d[1][1]]))\n",
    "        item_neg_pool = set(deepcopy(train_item_neg_neighbor[d[1][1]]))\n",
    "        \n",
    "        if d[1][2] == 1:\n",
    "            user_pos_pool.remove(d[1])\n",
    "            item_pos_pool.remove((d[1][0],d[0],d[1][2]))\n",
    "        elif d[1][2] == 0:\n",
    "            user_neg_pool.remove(d[1])\n",
    "            item_neg_pool.remove((d[1][0],d[0],d[1][2]))\n",
    "        else:\n",
    "            raise ValueError('Error!')\n",
    "        \n",
    "        user_pos_pool = list(user_pos_pool)\n",
    "        item_pos_pool = list(item_pos_pool)\n",
    "        user_neg_pool = list(user_neg_pool)\n",
    "        item_neg_pool = list(item_neg_pool)\n",
    "        random.shuffle(user_pos_pool)\n",
    "        random.shuffle(user_neg_pool)\n",
    "        random.shuffle(item_pos_pool)\n",
    "        random.shuffle(item_neg_pool)\n",
    "        \n",
    "        # sample for user\n",
    "        if len(user_pos_pool) >= upos:\n",
    "            user_pos_samples = user_pos_pool[:upos]\n",
    "        else:\n",
    "            user_pos_samples = user_pos_pool + [('',-1)] * (upos-len(user_pos_pool))\n",
    "        \n",
    "        if len(user_neg_pool) >= uneg:\n",
    "            user_neg_samples = user_neg_pool[:uneg]\n",
    "        else:\n",
    "            user_neg_samples = user_neg_pool + [('',-1)] * (uneg-len(user_neg_pool))\n",
    "        \n",
    "        # sample for item\n",
    "        if len(item_pos_pool) >= ipos:\n",
    "            item_pos_samples = item_pos_pool[:ipos]\n",
    "        else:\n",
    "            item_pos_samples = item_pos_pool + [('',-1)] * (ipos-len(item_pos_pool))\n",
    "        \n",
    "        if len(item_neg_pool) >= ineg:\n",
    "            item_neg_samples = item_neg_pool[:ineg]\n",
    "        else:\n",
    "            item_neg_samples = item_neg_pool + [('',-1)] * (ineg-len(item_neg_pool))\n",
    "        \n",
    "        # prepare for writing file\n",
    "        user_pos_text = '\\t'.join([up[0] for up in user_pos_samples])\n",
    "        user_pos_neighbor = '\\t'.join([str(item_id2idx[up[1]]) if up[1] != -1 else str(-1) for up in user_pos_samples])\n",
    "        user_neg_text = '\\t'.join([un[0] for un in user_neg_samples])\n",
    "        user_neg_neighbor = '\\t'.join([str(item_id2idx[un[1]]) if un[1] != -1 else str(-1) for un in user_neg_samples])\n",
    "        \n",
    "        item_pos_text = '\\t'.join([ip[0] for ip in item_pos_samples])\n",
    "        item_pos_neighbor = '\\t'.join([str(user_id2idx[ip[1]]) if ip[1] != -1 else str(-1) for ip in item_pos_samples])\n",
    "        item_neg_text = '\\t'.join([inn[0] for inn in item_neg_samples])\n",
    "        item_neg_neighbor = '\\t'.join([str(user_id2idx[inn[1]]) if inn[1] != -1 else str(-1) for inn in item_neg_samples])\n",
    "        \n",
    "        user_line = str(user_id2idx[d[0]]) + '\\*\\*' + user_pos_text + '\\*\\*' + user_neg_text + '\\*\\*' + user_pos_neighbor + '\\*\\*' + user_neg_neighbor\n",
    "        item_line = str(item_id2idx[d[1][1]]) + '\\*\\*' + item_pos_text + '\\*\\*' + item_neg_text + '\\*\\*' + item_pos_neighbor + '\\*\\*' + item_neg_neighbor\n",
    "        \n",
    "        fout.write(user_line+'\\$\\$'+item_line+'\\$\\$'+str(d[1][2])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1af48f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67801/67801 [01:28<00:00, 763.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Valid Dev Edges:60323 | Total:67801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# generate and save val file (make sure to delete items that are not in train set)\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "valid_dev_edges = 0\n",
    "\n",
    "with open(f'{output_dir}/{dataset}/val.tsv','w') as fout:\n",
    "    for d in tqdm(val_tuples):\n",
    "        # if item not in train item set, continue\n",
    "        if d[1][1] not in train_item_set:\n",
    "            continue\n",
    "\n",
    "        # counting\n",
    "        valid_dev_edges += 1\n",
    "\n",
    "        # prepare sample pool for user and item\n",
    "        user_pos_pool = deepcopy(train_user_pos_neighbor[d[0]])\n",
    "        user_neg_pool = deepcopy(train_user_neg_neighbor[d[0]])\n",
    "        item_pos_pool = deepcopy(train_item_pos_neighbor[d[1][1]])\n",
    "        item_neg_pool = deepcopy(train_item_neg_neighbor[d[1][1]])\n",
    "        \n",
    "        random.shuffle(user_pos_pool)\n",
    "        random.shuffle(user_neg_pool)\n",
    "        random.shuffle(item_pos_pool)\n",
    "        random.shuffle(item_neg_pool)\n",
    "        \n",
    "        # sample for user\n",
    "        if len(user_pos_pool) >= upos:\n",
    "            user_pos_samples = user_pos_pool[:upos]\n",
    "        else:\n",
    "            user_pos_samples = user_pos_pool + [('',-1)] * (upos-len(user_pos_pool))\n",
    "        \n",
    "        if len(user_neg_pool) >= uneg:\n",
    "            user_neg_samples = user_neg_pool[:uneg]\n",
    "        else:\n",
    "            user_neg_samples = user_neg_pool + [('',-1)] * (uneg-len(user_neg_pool))\n",
    "        \n",
    "        # sample for item\n",
    "        if len(item_pos_pool) >= ipos:\n",
    "            item_pos_samples = item_pos_pool[:ipos]\n",
    "        else:\n",
    "            item_pos_samples = item_pos_pool + [('',-1)] * (ipos-len(item_pos_pool))\n",
    "        \n",
    "        if len(item_neg_pool) >= ineg:\n",
    "            item_neg_samples = item_neg_pool[:ineg]\n",
    "        else:\n",
    "            item_neg_samples = item_neg_pool + [('',-1)] * (ineg-len(item_neg_pool))\n",
    "        \n",
    "        # prepare for writing file\n",
    "        user_pos_text = '\\t'.join([up[0] for up in user_pos_samples])\n",
    "        user_pos_neighbor = '\\t'.join([str(item_id2idx[up[1]]) if up[1] != -1 else str(-1) for up in user_pos_samples])\n",
    "        user_neg_text = '\\t'.join([un[0] for un in user_neg_samples])\n",
    "        user_neg_neighbor = '\\t'.join([str(item_id2idx[un[1]]) if un[1] != -1 else str(-1) for un in user_neg_samples])\n",
    "        \n",
    "        item_pos_text = '\\t'.join([ip[0] for ip in item_pos_samples])\n",
    "        item_pos_neighbor = '\\t'.join([str(user_id2idx[ip[1]]) if ip[1] != -1 else str(-1) for ip in item_pos_samples])\n",
    "        item_neg_text = '\\t'.join([inn[0] for inn in item_neg_samples])\n",
    "        item_neg_neighbor = '\\t'.join([str(user_id2idx[inn[1]]) if inn[1] != -1 else str(-1) for inn in item_neg_samples])\n",
    "        \n",
    "        user_line = str(user_id2idx[d[0]]) + '\\*\\*' + user_pos_text + '\\*\\*' + user_neg_text + '\\*\\*' + user_pos_neighbor + '\\*\\*' + user_neg_neighbor\n",
    "        item_line = str(item_id2idx[d[1][1]]) + '\\*\\*' + item_pos_text + '\\*\\*' + item_neg_text + '\\*\\*' + item_pos_neighbor + '\\*\\*' + item_neg_neighbor\n",
    "        \n",
    "        fout.write(user_line+'\\$\\$'+item_line+'\\$\\$'+str(d[1][2])+'\\n')\n",
    "\n",
    "print(f'Number of Valid Dev Edges:{valid_dev_edges} | Total:{len(val_tuples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b14bc30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203808/203808 [04:28<00:00, 759.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Valid Test Edges:182238 | Total:203808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# generate and save test file (make sure to delete items that are not in train set)\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "valid_test_edges = 0\n",
    "\n",
    "with open(f'{output_dir}/{dataset}/test.tsv','w') as fout:\n",
    "    for d in tqdm(test_tuples):\n",
    "        # if item not in train item set, continue\n",
    "        if d[1][1] not in train_item_set:\n",
    "            continue\n",
    "\n",
    "        # counting\n",
    "        valid_test_edges += 1\n",
    "\n",
    "        # prepare sample pool for user and item\n",
    "        user_pos_pool = deepcopy(train_user_pos_neighbor[d[0]])\n",
    "        user_neg_pool = deepcopy(train_user_neg_neighbor[d[0]])\n",
    "        item_pos_pool = deepcopy(train_item_pos_neighbor[d[1][1]])\n",
    "        item_neg_pool = deepcopy(train_item_neg_neighbor[d[1][1]])\n",
    "        \n",
    "        random.shuffle(user_pos_pool)\n",
    "        random.shuffle(user_neg_pool)\n",
    "        random.shuffle(item_pos_pool)\n",
    "        random.shuffle(item_neg_pool)\n",
    "        \n",
    "        # sample for user\n",
    "        if len(user_pos_pool) >= upos:\n",
    "            user_pos_samples = user_pos_pool[:upos]\n",
    "        else:\n",
    "            user_pos_samples = user_pos_pool + [('',-1)] * (upos-len(user_pos_pool))\n",
    "        \n",
    "        if len(user_neg_pool) >= uneg:\n",
    "            user_neg_samples = user_neg_pool[:uneg]\n",
    "        else:\n",
    "            user_neg_samples = user_neg_pool + [('',-1)] * (uneg-len(user_neg_pool))\n",
    "        \n",
    "        # sample for item\n",
    "        if len(item_pos_pool) >= ipos:\n",
    "            item_pos_samples = item_pos_pool[:ipos]\n",
    "        else:\n",
    "            item_pos_samples = item_pos_pool + [('',-1)] * (ipos-len(item_pos_pool))\n",
    "        \n",
    "        if len(item_neg_pool) >= ineg:\n",
    "            item_neg_samples = item_neg_pool[:ineg]\n",
    "        else:\n",
    "            item_neg_samples = item_neg_pool + [('',-1)] * (ineg-len(item_neg_pool))\n",
    "        \n",
    "        # prepare for writing file\n",
    "        user_pos_text = '\\t'.join([up[0] for up in user_pos_samples])\n",
    "        user_pos_neighbor = '\\t'.join([str(item_id2idx[up[1]]) if up[1] != -1 else str(-1) for up in user_pos_samples])\n",
    "        user_neg_text = '\\t'.join([un[0] for un in user_neg_samples])\n",
    "        user_neg_neighbor = '\\t'.join([str(item_id2idx[un[1]]) if un[1] != -1 else str(-1) for un in user_neg_samples])\n",
    "        \n",
    "        item_pos_text = '\\t'.join([ip[0] for ip in item_pos_samples])\n",
    "        item_pos_neighbor = '\\t'.join([str(user_id2idx[ip[1]]) if ip[1] != -1 else str(-1) for ip in item_pos_samples])\n",
    "        item_neg_text = '\\t'.join([inn[0] for inn in item_neg_samples])\n",
    "        item_neg_neighbor = '\\t'.join([str(user_id2idx[inn[1]]) if inn[1] != -1 else str(-1) for inn in item_neg_samples])\n",
    "        \n",
    "        user_line = str(user_id2idx[d[0]]) + '\\*\\*' + user_pos_text + '\\*\\*' + user_neg_text + '\\*\\*' + user_pos_neighbor + '\\*\\*' + user_neg_neighbor\n",
    "        item_line = str(item_id2idx[d[1][1]]) + '\\*\\*' + item_pos_text + '\\*\\*' + item_neg_text + '\\*\\*' + item_pos_neighbor + '\\*\\*' + item_neg_neighbor\n",
    "        \n",
    "        fout.write(user_line+'\\$\\$'+item_line+'\\$\\$'+str(d[1][2])+'\\n')\n",
    "\n",
    "print(f'Number of Valid Test Edges:{valid_test_edges} | Total:{len(test_tuples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22662de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save side files\n",
    "\n",
    "pickle.dump([upos,uneg,ipos,ineg],open(f'{output_dir}/{dataset}/neighbor_sampling.pkl','wb'))\n",
    "pickle.dump(user_id2idx,open(f'{output_dir}/{dataset}/user_id2idx.pkl','wb'))\n",
    "pickle.dump(item_id2idx,open(f'{output_dir}/{dataset}/item_id2idx.pkl','wb'))\n",
    "pickle.dump([len(user_id2idx),len(item_id2idx),2],open(f'{output_dir}/{dataset}/node_num.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2092165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save neighbor file\n",
    "\n",
    "pickle.dump(train_user_pos_neighbor,open(f'{output_dir}/{dataset}/neighbor/train_user_pos_neighbor.pkl','wb'))\n",
    "pickle.dump(train_user_neg_neighbor,open(f'{output_dir}/{dataset}/neighbor/train_user_neg_neighbor.pkl','wb'))\n",
    "pickle.dump(train_item_pos_neighbor,open(f'{output_dir}/{dataset}/neighbor/train_item_pos_neighbor.pkl','wb'))\n",
    "pickle.dump(train_item_neg_neighbor,open(f'{output_dir}/{dataset}/neighbor/train_item_neg_neighbor.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ed79ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3813db64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
