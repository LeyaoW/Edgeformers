{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f795fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from transformers import BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "667e1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf349bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Apps'  # Electronics, movie, CDs\n",
    "data_name = 'reviews_Apps_for_Android_5' # reviews_Electronics_5, reviews_CDs_and_Vinyl_5\n",
    "output_dir = 'xxx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baddf92",
   "metadata": {},
   "source": [
    "# Generate Training Data (Link Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba7e9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 752937/752937 [00:08<00:00, 91726.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# read raw data\n",
    "with open(f'{dataset}/{data_name}.json') as f:\n",
    "    data = []\n",
    "    readin = f.readlines()\n",
    "    for line in tqdm(readin):\n",
    "        data.append(json.loads(line))\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6ff75f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752937"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "931180b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reviewerID': 'A2YSTKGII86WNU',\n",
       " 'asin': 'B0073XT3GY',\n",
       " 'reviewerName': 'PaulGo',\n",
       " 'helpful': [2, 4],\n",
       " 'reviewText': 'I have the Samsung Galaxy S Captivate with the Gingerbread OS and the app will either crash, cause the phone to shut down, or state that it cannot contact the Amazon Appstore.  I uninstalled this app.',\n",
       " 'overall': 1.0,\n",
       " 'summary': 'Does Not Work On Captivate',\n",
       " 'unixReviewTime': 1339372800,\n",
       " 'reviewTime': '06 11, 2012'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49f8fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text processing function\n",
    "def text_process(text):\n",
    "    p_text = ' '.join(text.split('\\r\\n'))\n",
    "    p_text = ' '.join(text.split('\\n\\r'))\n",
    "    p_text = ' '.join(text.split('\\n'))\n",
    "    p_text = ' '.join(p_text.split('\\t'))\n",
    "    p_text = ' '.join(p_text.split('\\rm'))\n",
    "    p_text = ' '.join(p_text.split('\\r'))\n",
    "    p_text = ''.join(p_text.split('$'))\n",
    "    p_text = ''.join(p_text.split('*'))\n",
    "\n",
    "    return p_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "139bfffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 752937/752937 [00:00<00:00, 1136833.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {2.0: 44385, 3.0: 85121, 5.0: 386637, 1.0: 78713, 4.0: 158081})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## rate distribution\n",
    "\n",
    "rate_dict = defaultdict(int)\n",
    "\n",
    "for d in tqdm(data):\n",
    "    rate_dict[d['overall']] += 1\n",
    "    \n",
    "print(rate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c0eff9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 752937/752937 [00:05<00:00, 127595.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blank review:0\n",
      "Number of user:87271, Number of item:13209\n",
      "user_pos_reviews.len:82369,user_neg_reviews.len:79454\n",
      "item_pos_reviews.len:12536,item_neg_reviews.len:13107\n",
      "user.avg.pos_review:4.430303308086306,user.avg.neg_review:4.19727057098005\n",
      "item.avg.pos_review:29.270724506018624,item.avg.neg_review:27.73109243697479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## user/item statistics\n",
    "### we see 5 score as positive edge(review), 1-4 as negative ones.\n",
    "### user_pos_reviews/user_neg_reviews: key<-userID, value<-list(reviews)\n",
    "### item_pos_reviews/item_neg_reviews: key<-productID, value<-list(reviews)\n",
    "### user_reviews_dict/item_reviews_dict: key<-userID/productID, value<-list(tuple(reviews,p/n))\n",
    "\n",
    "user_pos_reviews = defaultdict(list)\n",
    "user_neg_reviews = defaultdict(list)\n",
    "item_pos_reviews = defaultdict(list)\n",
    "item_neg_reviews = defaultdict(list)\n",
    "user_set = set()\n",
    "item_set = set()\n",
    "\n",
    "user_reviews_dict = defaultdict(list)\n",
    "item_reviews_dict = defaultdict(list)\n",
    "\n",
    "blank_review_cnt = 0\n",
    "\n",
    "for d in tqdm(data):\n",
    "    if 'reviewText' not in d:\n",
    "    #if 'summary' not in d:\n",
    "        blank_review_cnt += 1\n",
    "        continue\n",
    "    \n",
    "    text = text_process(d['reviewText'])\n",
    "    #text = text_process(d['summary'])\n",
    "    user_set.add(d['reviewerID'])\n",
    "    item_set.add(d['asin'])\n",
    "    if d['overall'] == 5.0:\n",
    "        user_pos_reviews[d['reviewerID']].append(text)\n",
    "        item_pos_reviews[d['asin']].append(text)\n",
    "        \n",
    "        user_reviews_dict[d['reviewerID']].append((text,d['asin'],1))\n",
    "        item_reviews_dict[d['asin']].append((text,d['reviewerID'],1))\n",
    "    elif d['overall'] in [1,2,3,4]:\n",
    "        user_neg_reviews[d['reviewerID']].append(text)\n",
    "        item_neg_reviews[d['asin']].append(text)\n",
    "        \n",
    "        user_reviews_dict[d['reviewerID']].append((text,d['asin'],0))\n",
    "        item_reviews_dict[d['asin']].append((text,d['reviewerID'],0))\n",
    "    else:\n",
    "        raise ValueError('Error!')\n",
    "        \n",
    "print(f'Number of blank review:{blank_review_cnt}')\n",
    "print(f'Number of user:{len(user_set)}, Number of item:{len(item_set)}')\n",
    "print(f'user_pos_reviews.len:{len(user_pos_reviews)},user_neg_reviews.len:{len(user_neg_reviews)}')\n",
    "print(f'item_pos_reviews.len:{len(item_pos_reviews)},item_neg_reviews.len:{len(item_neg_reviews)}')\n",
    "print(f'user.avg.pos_review:{rate_dict[5]/len(user_set)},user.avg.neg_review:{(rate_dict[1]+rate_dict[2]+rate_dict[3]+rate_dict[4])/len(user_set)}')\n",
    "print(f'item.avg.pos_review:{rate_dict[5]/len(item_set)},item.avg.neg_review:{(rate_dict[1]+rate_dict[2]+rate_dict[3]+rate_dict[4])/len(item_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "691d2a4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87271/87271 [00:01<00:00, 44621.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of item appearing in train_set:13197 or 13197\n",
      "Train/Val/Test size:486489,84214,182234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## split train/val/test as 7:1:2 or 8:1:1\n",
    "### user_pos_reviews/user_neg_reviews: key<-userID, value<-list(reviews)\n",
    "### item_pos_reviews/item_neg_reviews: key<-productID, value<-list(reviews)\n",
    "### train_user_neighbor: key<-userID, value<-list(tuple(reviews,p/n))\n",
    "### train_item_neighbor: key<-userID, value<-list(tuple(reviews,p/n))\n",
    "\n",
    "sample_num = len(data)\n",
    "random.seed(0)\n",
    "\n",
    "train_tuples = []\n",
    "val_tuples = []\n",
    "test_tuples = []\n",
    "train_item_set = set()\n",
    "user_id2idx = {}\n",
    "item_id2idx = {}\n",
    "train_user_pos_neighbor = defaultdict(list)\n",
    "train_user_neg_neighbor = defaultdict(list)\n",
    "train_item_pos_neighbor = defaultdict(list)\n",
    "train_item_neg_neighbor = defaultdict(list)\n",
    "\n",
    "c1 = 0\n",
    "c2 = 0\n",
    "c3 = 0\n",
    "\n",
    "for uid in tqdm(user_reviews_dict):\n",
    "    if uid not in user_id2idx:\n",
    "        user_id2idx[uid] = len(user_id2idx)\n",
    "    random.shuffle(user_reviews_dict[uid])\n",
    "    \n",
    "    for i in range(int(len(user_reviews_dict[uid])*0.7)):\n",
    "    #for i in range(int(len(user_reviews_dict[uid])*0.8)):\n",
    "        train_tuples.append((uid,user_reviews_dict[uid][i]))\n",
    "        train_item_set.add(user_reviews_dict[uid][i][1])\n",
    "        \n",
    "        # add to item_id2idx\n",
    "        if user_reviews_dict[uid][i][1] not in item_id2idx:\n",
    "            item_id2idx[user_reviews_dict[uid][i][1]] = len(item_id2idx)\n",
    "\n",
    "        # add to train_user_neighbor/train_item_neighbor\n",
    "        if user_reviews_dict[uid][i][2] == 1:\n",
    "            train_user_pos_neighbor[uid].append(user_reviews_dict[uid][i])\n",
    "            train_item_pos_neighbor[user_reviews_dict[uid][i][1]].append((user_reviews_dict[uid][i][0],uid,user_reviews_dict[uid][i][2]))\n",
    "        elif user_reviews_dict[uid][i][2] == 0:\n",
    "            train_user_neg_neighbor[uid].append(user_reviews_dict[uid][i])\n",
    "            train_item_neg_neighbor[user_reviews_dict[uid][i][1]].append((user_reviews_dict[uid][i][0],uid,user_reviews_dict[uid][i][2]))\n",
    "        else:\n",
    "            raise ValueError('Error!')\n",
    "            \n",
    "    for i in range(int(len(user_reviews_dict[uid])*0.7),int(len(user_reviews_dict[uid])*0.8)):\n",
    "    #for i in range(int(len(user_reviews_dict[uid])*0.8),int(len(user_reviews_dict[uid])*0.9)):\n",
    "        val_tuples.append((uid,user_reviews_dict[uid][i]))\n",
    "\n",
    "    for i in range(int(len(user_reviews_dict[uid])*0.8),len(user_reviews_dict[uid])):\n",
    "    #for i in range(int(len(user_reviews_dict[uid])*0.9),len(user_reviews_dict[uid])):\n",
    "        test_tuples.append((uid,user_reviews_dict[uid][i]))\n",
    "        \n",
    "print(f'Number of item appearing in train_set:{len(train_item_set)} or {len(item_id2idx)}')\n",
    "print(f'Train/Val/Test size:{len(train_tuples)},{len(val_tuples)},{len(test_tuples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6e668bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 486489/486489 [14:09<00:00, 572.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# generate and save train file\n",
    "## user pos neighbor: 8/2, user neg neighbor: 8/2\n",
    "## item pos neighbor: 10/5, item neg neighbor: 10/5\n",
    "\n",
    "upos = 3\n",
    "uneg = 3\n",
    "ipos = 5\n",
    "ineg = 5\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "with open(f'{output_dir}/{dataset}/train.tsv','w') as fout:\n",
    "    for d in tqdm(train_tuples):\n",
    "        \n",
    "        # prepare sample pool for user and item\n",
    "        user_pos_pool = set(deepcopy(train_user_pos_neighbor[d[0]]))\n",
    "        user_neg_pool = set(deepcopy(train_user_neg_neighbor[d[0]]))\n",
    "        item_pos_pool = set(deepcopy(train_item_pos_neighbor[d[1][1]]))\n",
    "        item_neg_pool = set(deepcopy(train_item_neg_neighbor[d[1][1]]))\n",
    "        \n",
    "        if d[1][2] == 1:\n",
    "            user_pos_pool.remove(d[1])\n",
    "            item_pos_pool.remove((d[1][0],d[0],d[1][2]))\n",
    "        elif d[1][2] == 0:\n",
    "            user_neg_pool.remove(d[1])\n",
    "            item_neg_pool.remove((d[1][0],d[0],d[1][2]))\n",
    "        else:\n",
    "            raise ValueError('Error!')\n",
    "        \n",
    "        user_pos_pool = list(user_pos_pool)\n",
    "        item_pos_pool = list(item_pos_pool)\n",
    "        user_neg_pool = list(user_neg_pool)\n",
    "        item_neg_pool = list(item_neg_pool)\n",
    "        random.shuffle(user_pos_pool)\n",
    "        random.shuffle(user_neg_pool)\n",
    "        random.shuffle(item_pos_pool)\n",
    "        random.shuffle(item_neg_pool)\n",
    "        \n",
    "        # sample for user\n",
    "        if len(user_pos_pool) >= upos:\n",
    "            user_pos_samples = user_pos_pool[:upos]\n",
    "        else:\n",
    "            user_pos_samples = user_pos_pool + [('',-1)] * (upos-len(user_pos_pool))\n",
    "        \n",
    "        if len(user_neg_pool) >= uneg:\n",
    "            user_neg_samples = user_neg_pool[:uneg]\n",
    "        else:\n",
    "            user_neg_samples = user_neg_pool + [('',-1)] * (uneg-len(user_neg_pool))\n",
    "        \n",
    "        # sample for item\n",
    "        if len(item_pos_pool) >= ipos:\n",
    "            item_pos_samples = item_pos_pool[:ipos]\n",
    "        else:\n",
    "            item_pos_samples = item_pos_pool + [('',-1)] * (ipos-len(item_pos_pool))\n",
    "        \n",
    "        if len(item_neg_pool) >= ineg:\n",
    "            item_neg_samples = item_neg_pool[:ineg]\n",
    "        else:\n",
    "            item_neg_samples = item_neg_pool + [('',-1)] * (ineg-len(item_neg_pool))\n",
    "        \n",
    "        # prepare for writing file\n",
    "        user_pos_text = '\\t'.join([up[0] for up in user_pos_samples])\n",
    "        user_pos_neighbor = '\\t'.join([str(item_id2idx[up[1]]) if up[1] != -1 else str(-1) for up in user_pos_samples])\n",
    "        user_neg_text = '\\t'.join([un[0] for un in user_neg_samples])\n",
    "        user_neg_neighbor = '\\t'.join([str(item_id2idx[un[1]]) if un[1] != -1 else str(-1) for un in user_neg_samples])\n",
    "        \n",
    "        item_pos_text = '\\t'.join([ip[0] for ip in item_pos_samples])\n",
    "        item_pos_neighbor = '\\t'.join([str(user_id2idx[ip[1]]) if ip[1] != -1 else str(-1) for ip in item_pos_samples])\n",
    "        item_neg_text = '\\t'.join([inn[0] for inn in item_neg_samples])\n",
    "        item_neg_neighbor = '\\t'.join([str(user_id2idx[inn[1]]) if inn[1] != -1 else str(-1) for inn in item_neg_samples])\n",
    "        \n",
    "        user_line = str(user_id2idx[d[0]]) + '\\*\\*' + user_pos_text + '\\*\\*' + user_neg_text + '\\*\\*' + user_pos_neighbor + '\\*\\*' + user_neg_neighbor\n",
    "        item_line = str(item_id2idx[d[1][1]]) + '\\*\\*' + item_pos_text + '\\*\\*' + item_neg_text + '\\*\\*' + item_pos_neighbor + '\\*\\*' + item_neg_neighbor\n",
    "        \n",
    "        fout.write(user_line+'\\$\\$'+item_line+'\\$\\$'+str(d[1][2])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1af48f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84214/84214 [02:23<00:00, 585.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Valid Dev Edges:84197 | Total:84214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# generate and save val file (make sure to delete items that are not in train set)\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "valid_dev_edges = 0\n",
    "\n",
    "with open(f'{output_dir}/{dataset}/val.tsv','w') as fout:\n",
    "    for d in tqdm(val_tuples):\n",
    "        # if item not in train item set, continue\n",
    "        if d[1][1] not in train_item_set:\n",
    "            continue\n",
    "\n",
    "        # counting\n",
    "        valid_dev_edges += 1\n",
    "\n",
    "        # prepare sample pool for user and item\n",
    "        user_pos_pool = deepcopy(train_user_pos_neighbor[d[0]])\n",
    "        user_neg_pool = deepcopy(train_user_neg_neighbor[d[0]])\n",
    "        item_pos_pool = deepcopy(train_item_pos_neighbor[d[1][1]])\n",
    "        item_neg_pool = deepcopy(train_item_neg_neighbor[d[1][1]])\n",
    "        \n",
    "        random.shuffle(user_pos_pool)\n",
    "        random.shuffle(user_neg_pool)\n",
    "        random.shuffle(item_pos_pool)\n",
    "        random.shuffle(item_neg_pool)\n",
    "        \n",
    "        # sample for user\n",
    "        if len(user_pos_pool) >= upos:\n",
    "            user_pos_samples = user_pos_pool[:upos]\n",
    "        else:\n",
    "            user_pos_samples = user_pos_pool + [('',-1)] * (upos-len(user_pos_pool))\n",
    "        \n",
    "        if len(user_neg_pool) >= uneg:\n",
    "            user_neg_samples = user_neg_pool[:uneg]\n",
    "        else:\n",
    "            user_neg_samples = user_neg_pool + [('',-1)] * (uneg-len(user_neg_pool))\n",
    "        \n",
    "        # sample for item\n",
    "        if len(item_pos_pool) >= ipos:\n",
    "            item_pos_samples = item_pos_pool[:ipos]\n",
    "        else:\n",
    "            item_pos_samples = item_pos_pool + [('',-1)] * (ipos-len(item_pos_pool))\n",
    "        \n",
    "        if len(item_neg_pool) >= ineg:\n",
    "            item_neg_samples = item_neg_pool[:ineg]\n",
    "        else:\n",
    "            item_neg_samples = item_neg_pool + [('',-1)] * (ineg-len(item_neg_pool))\n",
    "        \n",
    "        # prepare for writing file\n",
    "        user_pos_text = '\\t'.join([up[0] for up in user_pos_samples])\n",
    "        user_pos_neighbor = '\\t'.join([str(item_id2idx[up[1]]) if up[1] != -1 else str(-1) for up in user_pos_samples])\n",
    "        user_neg_text = '\\t'.join([un[0] for un in user_neg_samples])\n",
    "        user_neg_neighbor = '\\t'.join([str(item_id2idx[un[1]]) if un[1] != -1 else str(-1) for un in user_neg_samples])\n",
    "        \n",
    "        item_pos_text = '\\t'.join([ip[0] for ip in item_pos_samples])\n",
    "        item_pos_neighbor = '\\t'.join([str(user_id2idx[ip[1]]) if ip[1] != -1 else str(-1) for ip in item_pos_samples])\n",
    "        item_neg_text = '\\t'.join([inn[0] for inn in item_neg_samples])\n",
    "        item_neg_neighbor = '\\t'.join([str(user_id2idx[inn[1]]) if inn[1] != -1 else str(-1) for inn in item_neg_samples])\n",
    "        \n",
    "        user_line = str(user_id2idx[d[0]]) + '\\*\\*' + user_pos_text + '\\*\\*' + user_neg_text + '\\*\\*' + user_pos_neighbor + '\\*\\*' + user_neg_neighbor\n",
    "        item_line = str(item_id2idx[d[1][1]]) + '\\*\\*' + item_pos_text + '\\*\\*' + item_neg_text + '\\*\\*' + item_pos_neighbor + '\\*\\*' + item_neg_neighbor\n",
    "        \n",
    "        fout.write(user_line+'\\$\\$'+item_line+'\\$\\$'+str(d[1][2])+'\\n')\n",
    "\n",
    "print(f'Number of Valid Dev Edges:{valid_dev_edges} | Total:{len(val_tuples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b14bc30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182234/182234 [05:14<00:00, 579.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Valid Test Edges:182184 | Total:182234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# generate and save test file (make sure to delete items that are not in train set)\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "valid_test_edges = 0\n",
    "\n",
    "with open(f'{output_dir}/{dataset}/test.tsv','w') as fout:\n",
    "    for d in tqdm(test_tuples):\n",
    "        # if item not in train item set, continue\n",
    "        if d[1][1] not in train_item_set:\n",
    "            continue\n",
    "\n",
    "        # counting\n",
    "        valid_test_edges += 1\n",
    "\n",
    "        # prepare sample pool for user and item\n",
    "        user_pos_pool = deepcopy(train_user_pos_neighbor[d[0]])\n",
    "        user_neg_pool = deepcopy(train_user_neg_neighbor[d[0]])\n",
    "        item_pos_pool = deepcopy(train_item_pos_neighbor[d[1][1]])\n",
    "        item_neg_pool = deepcopy(train_item_neg_neighbor[d[1][1]])\n",
    "        \n",
    "        random.shuffle(user_pos_pool)\n",
    "        random.shuffle(user_neg_pool)\n",
    "        random.shuffle(item_pos_pool)\n",
    "        random.shuffle(item_neg_pool)\n",
    "        \n",
    "        # sample for user\n",
    "        if len(user_pos_pool) >= upos:\n",
    "            user_pos_samples = user_pos_pool[:upos]\n",
    "        else:\n",
    "            user_pos_samples = user_pos_pool + [('',-1)] * (upos-len(user_pos_pool))\n",
    "        \n",
    "        if len(user_neg_pool) >= uneg:\n",
    "            user_neg_samples = user_neg_pool[:uneg]\n",
    "        else:\n",
    "            user_neg_samples = user_neg_pool + [('',-1)] * (uneg-len(user_neg_pool))\n",
    "        \n",
    "        # sample for item\n",
    "        if len(item_pos_pool) >= ipos:\n",
    "            item_pos_samples = item_pos_pool[:ipos]\n",
    "        else:\n",
    "            item_pos_samples = item_pos_pool + [('',-1)] * (ipos-len(item_pos_pool))\n",
    "        \n",
    "        if len(item_neg_pool) >= ineg:\n",
    "            item_neg_samples = item_neg_pool[:ineg]\n",
    "        else:\n",
    "            item_neg_samples = item_neg_pool + [('',-1)] * (ineg-len(item_neg_pool))\n",
    "        \n",
    "        # prepare for writing file\n",
    "        user_pos_text = '\\t'.join([up[0] for up in user_pos_samples])\n",
    "        user_pos_neighbor = '\\t'.join([str(item_id2idx[up[1]]) if up[1] != -1 else str(-1) for up in user_pos_samples])\n",
    "        user_neg_text = '\\t'.join([un[0] for un in user_neg_samples])\n",
    "        user_neg_neighbor = '\\t'.join([str(item_id2idx[un[1]]) if un[1] != -1 else str(-1) for un in user_neg_samples])\n",
    "        \n",
    "        item_pos_text = '\\t'.join([ip[0] for ip in item_pos_samples])\n",
    "        item_pos_neighbor = '\\t'.join([str(user_id2idx[ip[1]]) if ip[1] != -1 else str(-1) for ip in item_pos_samples])\n",
    "        item_neg_text = '\\t'.join([inn[0] for inn in item_neg_samples])\n",
    "        item_neg_neighbor = '\\t'.join([str(user_id2idx[inn[1]]) if inn[1] != -1 else str(-1) for inn in item_neg_samples])\n",
    "        \n",
    "        user_line = str(user_id2idx[d[0]]) + '\\*\\*' + user_pos_text + '\\*\\*' + user_neg_text + '\\*\\*' + user_pos_neighbor + '\\*\\*' + user_neg_neighbor\n",
    "        item_line = str(item_id2idx[d[1][1]]) + '\\*\\*' + item_pos_text + '\\*\\*' + item_neg_text + '\\*\\*' + item_pos_neighbor + '\\*\\*' + item_neg_neighbor\n",
    "        \n",
    "        fout.write(user_line+'\\$\\$'+item_line+'\\$\\$'+str(d[1][2])+'\\n')\n",
    "\n",
    "print(f'Number of Valid Test Edges:{valid_test_edges} | Total:{len(test_tuples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22662de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save side files\n",
    "\n",
    "pickle.dump([upos,uneg,ipos,ineg],open(f'{output_dir}/{dataset}/neighbor_sampling.pkl','wb'))\n",
    "pickle.dump(user_id2idx,open(f'{output_dir}/{dataset}/user_id2idx.pkl','wb'))\n",
    "pickle.dump(item_id2idx,open(f'{output_dir}/{dataset}/item_id2idx.pkl','wb'))\n",
    "pickle.dump([len(user_id2idx),len(item_id2idx),2],open(f'{output_dir}/{dataset}/node_num.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2092165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save neighbor file\n",
    "\n",
    "pickle.dump(train_user_pos_neighbor,open(f'{output_dir}/{dataset}/neighbor/train_user_pos_neighbor.pkl','wb'))\n",
    "pickle.dump(train_user_neg_neighbor,open(f'{output_dir}/{dataset}/neighbor/train_user_neg_neighbor.pkl','wb'))\n",
    "pickle.dump(train_item_pos_neighbor,open(f'{output_dir}/{dataset}/neighbor/train_item_pos_neighbor.pkl','wb'))\n",
    "pickle.dump(train_item_neg_neighbor,open(f'{output_dir}/{dataset}/neighbor/train_item_neg_neighbor.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ed79ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b118f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
